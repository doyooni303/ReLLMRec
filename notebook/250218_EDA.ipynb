{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "fname=\"Books\"\n",
    "path = \"/DATA/Recommendation/amazon/Books\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def open_json(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        dict_list = [json.loads(line[:-1]) for line in f.readlines()]\n",
    "    return dict_list\n",
    "meta = open_json(os.path.join(path, f\"meta_{fname}.jsonl\"))\n",
    "data = open_json(os.path.join(path, f\"{fname}.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29475453/29475453 [00:36<00:00, 809289.28it/s] \n"
     ]
    }
   ],
   "source": [
    "interactions = []\n",
    "max_user = []\n",
    "for l in tqdm(data):\n",
    "    asin = l[\"asin\"]\n",
    "    rev = l[\"user_id\"]\n",
    "    time = l[\"timestamp\"]\n",
    "    interactions.append((asin, rev, time))\n",
    "    if rev ==\"AGSP6LSQK32SQEJO3YVVNACPWMSQ\":\n",
    "        max_user.append((asin, time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0380777606', 1106682486000),\n",
       " ('0867196653', 1187447270000),\n",
       " ('0345491939', 1190676200000),\n",
       " ('0345493982', 1190750723000),\n",
       " ('0451220277', 1191118866000),\n",
       " ('0061031151', 1191205206000),\n",
       " ('1421514087', 1191528759000),\n",
       " ('0061136158', 1191877881000),\n",
       " ('045146107X', 1191946751000),\n",
       " ('0446618241', 1192056675000),\n",
       " ('1598168754', 1192135385000),\n",
       " ('0425201503', 1192150505000),\n",
       " ('044661579X', 1192454150000),\n",
       " ('1421514079', 1195592742000),\n",
       " ('1897299060', 1195932693000),\n",
       " ('0758213719', 1196644721000),\n",
       " ('1599983540', 1200686421000),\n",
       " ('142151477X', 1200731356000),\n",
       " ('1427803145', 1200738857000),\n",
       " ('1427803307', 1201497956000)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_user = sorted(max_user, key=lambda x: x[1])\n",
    "max_user[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = set(interactions)\n",
    "countU = defaultdict(lambda : 0)\n",
    "for asin, rev, time in interactions:\n",
    "    countU[rev] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3888, 'AGSP6LSQK32SQEJO3YVVNACPWMSQ')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(countU.values())[21350],list(countU.keys())[21350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21350"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.percentile(list(countU.values()),q=[0,25,50,75,100])\n",
    "np.argmax(list(countU.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150206/1150206 [00:04<00:00, 279350.21it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "txt = open(os.path.join(path, f\"train.txt\"), \"r\").readlines()\n",
    "train = dict()\n",
    "counter = Counter()\n",
    "train_items = list()\n",
    "for line in tqdm(txt):\n",
    "    u, history = line.rstrip().split(\":\")\n",
    "    history = [int(i) for i in history.split(\" \")]\n",
    "    train_items.extend(history)\n",
    "    u = int(u)\n",
    "    train.update({u: history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12187673/12187673 [00:16<00:00, 749638.31it/s]\n"
     ]
    }
   ],
   "source": [
    "txt = open(os.path.join(path, f\"{fname}.txt\"), \"r\").readlines()\n",
    "total = defaultdict(list)\n",
    "counter = Counter()\n",
    "total_items = list()\n",
    "for line in tqdm(txt):\n",
    "    u, i = line.rstrip().split(\" \")\n",
    "    u = int(u)\n",
    "    i = int(i)\n",
    "    total[u].append(i)\n",
    "    total_items.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980848"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(total_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.365173716708138, 10.100337294681186)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_avg_len = np.mean([len(i) for i in train.values()])\n",
    "total_avg_len = np.mean([len(i) for i in total.values()])\n",
    "train_avg_len, total_avg_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess 재구성\n",
    "1) 중복제거\n",
    "2) interactions 수 5 미만 사용자, 아이템 제거\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29475453/29475453 [00:30<00:00, 962231.20it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "unique_interactions = list()\n",
    "\n",
    "for l in tqdm(data):\n",
    "    asin = l[\"asin\"]\n",
    "    rev = l[\"user_id\"]\n",
    "    time = l[\"timestamp\"]\n",
    "    interactions.append((asin, rev, time))\n",
    "unique_interactions = set(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/29475453 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29475453/29475453 [01:32<00:00, 318046.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# 중복 제거 완료\n",
    "data_list = list()\n",
    "countI, countU, countP = defaultdict(lambda : 0), defaultdict(lambda : 0), defaultdict(lambda : 0)\n",
    "for l in tqdm(data):\n",
    "    asin = l[\"asin\"]\n",
    "    rev = l[\"user_id\"]\n",
    "    time = l[\"timestamp\"]\n",
    "    key = f\"{asin}-{rev}-{time}\"\n",
    "    countI[key]+=1\n",
    "    if countI[key] >= 2:\n",
    "        continue\n",
    "    else:\n",
    "        countU[rev] += 1\n",
    "        countP[asin] += 1\n",
    "        data_list.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29142325, 29142325, 29142325)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list), sum(countU.values()), sum(countP.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading jsonl files..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29475453/29475453 [01:22<00:00, 355197.16it/s]\n",
      "100%|██████████| 29142325/29142325 [03:12<00:00, 151477.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Books_meta_name_dict.json\n",
      "1188598 969145\n",
      "Saved Books.txt\n",
      "Saved Books_usermap.json\n",
      "Saved Books_itemmap.json\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/doyooni303/experiments/LLMRec/ReLLMRec\")\n",
    "\n",
    "from src.dataset.data_preprocess import preprocess\n",
    "fname = \"Books\"\n",
    "folder = \"../../data/amazon/Books\"\n",
    "preprocess(fname, \"jsonl\", folder, True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) 최소 interaction 수 5 and train, valid, test 구분\n",
    "- train user의 최소 interactions 수 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12120726it [00:21, 574424.82it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import os\n",
    "usernum, itemnum = 0, 0\n",
    "User = defaultdict(list)\n",
    "f = tqdm(open(os.path.join(folder, f\"{fname}.txt\"), \"r\"))\n",
    "for line in f:\n",
    "    u, i = line.rstrip().split(\" \")\n",
    "    u = int(u)\n",
    "    i = int(i)\n",
    "    usernum = max(u, usernum)\n",
    "    itemnum = max(i, itemnum)\n",
    "    User[u].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260393"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_check = list()\n",
    "for u, l in User.items():\n",
    "    if len(l) < 5:\n",
    "        user_check.append(u)\n",
    "len(user_check)\n",
    "\n",
    "## 원래 소비 기록 횟수가 5회 이상인 사람들이 있었는데, 아이템 중 소비기록 횟수가 5회가 안 되는 것들이 제외되면서\n",
    "## 해당 사용자의 소비기록에서도 제외되어서 소비기록이 5회 미만인 사용자들이 생겼다.\n",
    "## 그래서 train의 최소 길이는 5로 설정해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books.txt exists\n",
      "splitting data by user: 100%|█████| 1188598/1188598 [00:03<00:00, 314041.36it/s]\n",
      "Initializing UserSimilarityFinder...\n",
      "Finding similar users for 928205 query users...\n",
      "Get batches: 100%|███████████████████████| 1813/1813 [00:00<00:00, 84198.17it/s]\n",
      "Processing batches: 100%|█████████████████| 1813/1813 [1:02:05<00:00,  2.06s/it]\n",
      "Saving results...\n",
      "All completed !\n"
     ]
    }
   ],
   "source": [
    "!python3 /home/doyooni303/experiments/LLMRec/ReLLMRec/src/dataset/get_similar_users.py --path /home/doyooni303/experiments/LLMRec/data/amazon/Books "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train, valid, test txt 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "splitting data by user: 100%|██████████| 1188598/1188598 [00:03<00:00, 317602.76it/s]\n",
      "Preprocessing history: 100%|██████████| 928205/928205 [00:00<00:00, 1228961.78it/s]\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "sys.path.append(\"/home/doyooni303/experiments/LLMRec/ReLLMRec/src/dataset\")\n",
    "\n",
    "from get_similar_users import pruning\n",
    "from utils import data_partition\n",
    "\n",
    "train, valid, test = data_partition(\"Books\", \"/home/doyooni303/experiments/LLMRec/data/amazon/Books\")\n",
    "train = pruning(train, 5, 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "splitting data by user: 100%|██████████| 1188598/1188598 [00:03<00:00, 303889.10it/s]\n",
      "100%|██████████| 928205/928205 [00:03<00:00, 278313.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SELFRec data to /home/doyooni303/experiments/LLMRec/data/amazon/Books\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/doyooni303/experiments/LLMRec/ReLLMRec/src\")\n",
    "from dataset.utils import save_SELFRec_data\n",
    "\n",
    "save_SELFRec_data(\"Books\", \"/home/doyooni303/experiments/LLMRec/data/amazon/Books\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
